{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5a892e",
   "metadata": {},
   "source": [
    "Шаблон для запуска парсинга: \\\n",
    "python parsing.py 2 True housedorf urls_housedorf.txt example.xlsx result_housedorf.xlsx \n",
    "python parsing.py 2 False falmec urls_falmec.txt result_housedorf.xlsx result.xlsx\n",
    "\n",
    "python generate_syn_report.py housedorf syn_report_housedorf.xlsx\n",
    "python generate_syn_report.py falmec syn_report_falmec.xlsx\n",
    "\n",
    "python compare.py falmec housedorf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf61f80",
   "metadata": {},
   "source": [
    "# Программа parsing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f4adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import PatternFill, Alignment\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import argparse\n",
    "import os\n",
    "from ruwordnet import RuWordNet\n",
    "import pymorphy2\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "synonyms_path='synonyms.txt'\n",
    "all_characteristics_path='all_characteristics.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17c34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------Спарсить данные------------------------------------------------------------------------\n",
    "\n",
    "# Функции для парсинга\n",
    "def parse_korting_page(html_code):\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "    tabs_lists = soup.find_all('ul', class_='tabs-settings__list')\n",
    "    data = {}\n",
    "\n",
    "    for ul in tabs_lists:\n",
    "        for li in ul.find_all('li'):\n",
    "            text = li.get_text(strip=True, separator=\"; \")\n",
    "            split_text = text.split(\":;\", 1)\n",
    "            if len(split_text) == 2:\n",
    "                key, value = split_text\n",
    "                data[key.strip()] = value.strip()\n",
    "            else:\n",
    "                data[split_text[0].strip()] = \"\"\n",
    "\n",
    "    return data\n",
    "\n",
    "def parse_dedietrich_page(html_code: str) -> dict:\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "    data = {}\n",
    "\n",
    "    # Проходим по всем div с классом characteristics__row\n",
    "    for row in soup.find_all('div', class_='characteristics__row'):\n",
    "        name_span = row.find('span', class_='characteristics__name')\n",
    "        value_span = row.find('span', class_='characteristics__property')\n",
    "        \n",
    "        if name_span and value_span:\n",
    "            key = name_span.find(text=True, recursive=False)\n",
    "            value = value_span.find(text=True, recursive=False)\n",
    "            if key and value:\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                data[key] = value\n",
    "\n",
    "    return data\n",
    "\n",
    "def parse_vzug_page(html_code: str) -> dict:\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "    data = {}\n",
    "    names = soup.find_all('td', class_='cell_name')\n",
    "    values = soup.find_all('td', class_='cell_value')\n",
    "\n",
    "    # Проходим по всем div с классом characteristics__row\n",
    "    for name, value in zip(names, values):\n",
    "        name_span = name.find('span')\n",
    "        value_span = value.find('span')\n",
    "        \n",
    "        if name_span and value_span:\n",
    "            key = name_span.find(text=True, recursive=False)\n",
    "            value = value_span.find(text=True, recursive=False)\n",
    "            if key and value:\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                data[key] = value\n",
    "\n",
    "    return data\n",
    "\n",
    "def parse_falmec_page(html_code: str) -> dict:\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "    data = {}\n",
    "\n",
    "    # Проходим по всем div с классом characteristics__row\n",
    "    for row in soup.find_all('div', class_='characteristics__row'):\n",
    "        name_span = row.find('span', class_='characteristics__name')\n",
    "        value_span = row.find('span', class_='characteristics__property')\n",
    "        \n",
    "        if name_span and value_span:\n",
    "            key = name_span.find(text=True, recursive=False)\n",
    "            value = value_span.find(text=True, recursive=False)\n",
    "\n",
    "            # Если нет простого текста, ищем <ul> и собираем <li>\n",
    "            if (value == '' or not value.strip()) and value_span.find('ul'):\n",
    "                li_items = value_span.find_all('li')\n",
    "                value = '; '.join(li.get_text(strip=True) for li in li_items)\n",
    "\n",
    "            if key and value:\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                data[key] = value\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_first_visible_text(tag):\n",
    "    for desc in tag.descendants:\n",
    "        if isinstance(desc, str):  # Это NavigableString\n",
    "            text = desc.strip()\n",
    "            if text:\n",
    "                return text\n",
    "    return None\n",
    "\n",
    "def clean_value_div(value_div):\n",
    "    # 1. Удалить все <span>\n",
    "    for span in value_div.find_all(\"span\"):\n",
    "        span.decompose()\n",
    "\n",
    "    # 2. Разделить по <br> — создаём список на основе HTML с разделителем\n",
    "    parts = str(value_div).split('<br')\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for part_html in parts:\n",
    "        # Восстанавливаем HTML-тег <br>, если он был отрезан\n",
    "        if not part_html.startswith('>'):\n",
    "            part_html = '<br' + part_html\n",
    "\n",
    "        part_soup = BeautifulSoup(part_html, 'html.parser')\n",
    "\n",
    "        # 3. Найти первый видимый текст\n",
    "        for desc in part_soup.descendants:\n",
    "            if isinstance(desc, NavigableString):\n",
    "                text = desc.strip()\n",
    "                if text:\n",
    "                    values.append(text)\n",
    "                    break  # только первое вхождение\n",
    "\n",
    "    # 4. Склеить с разделителем \"; \"\n",
    "    return \"; \".join(values)\n",
    "\n",
    "def parse_hausedorf_page(html_code):\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "    fields = soup.find_all('div', class_='detail-properties__field')\n",
    "    data = {}\n",
    "\n",
    "    for field in fields:\n",
    "        name_div = field.find('div', class_='detail-properties__name')\n",
    "        value_div = field.find('div', class_='detail-properties__value')\n",
    "\n",
    "        if name_div and value_div:\n",
    "            key = extract_first_visible_text(name_div)\n",
    "            value = clean_value_div(value_div)\n",
    "\n",
    "            if key and value:\n",
    "                data[re.sub(r'\\s+', ' ', key).strip()] = value.replace(\">\\n\", \"\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_src(file_path, parser_func):\n",
    "    \"\"\"\n",
    "    Универсальный загрузчик таблицы характеристик с разных сайтов.\n",
    "\n",
    "    :param file_path: путь к файлу с URL (один URL на строку)\n",
    "    :param parser_func: функция, которая получает HTML-код и возвращает словарь {ключ: значение}\n",
    "    :return: DataFrame с объединёнными результатами\n",
    "    \"\"\"\n",
    "    http = urllib3.PoolManager()\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        urls = [line.strip() for line in f]\n",
    "\n",
    "    n_rows = 0\n",
    "    for url in tqdm(urls):\n",
    "        if url:\n",
    "            try:\n",
    "                response = http.request('GET', url)\n",
    "                html_code = response.data.decode()\n",
    "                data = parser_func(html_code) \n",
    "\n",
    "                if not isinstance(data, dict):\n",
    "                    raise ValueError(\"parser_func должна возвращать словарь!\")\n",
    "\n",
    "                row_df = pd.DataFrame([data])\n",
    "                df_all = pd.concat([df_all, row_df], ignore_index=True)\n",
    "\n",
    "                if len(df_all) == 1:\n",
    "                    empty_rows = pd.DataFrame(np.nan, index=range(n_rows), columns=df_all.columns)\n",
    "                    df_all = pd.concat([empty_rows, df_all], ignore_index=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при обработке {url}: {e}\")\n",
    "        else:\n",
    "            if len(df_all.columns) > 0:                \n",
    "                df_all.loc[len(df_all)] = None\n",
    "            else:\n",
    "                n_rows += 1\n",
    "\n",
    "    return df_all.where(pd.notnull(df_all), None)\n",
    "\n",
    "# ---------------------------------------------Записать и вернуть дополненный названиями номенклатуры DataFrame---------------------------------------------\n",
    "\n",
    "def write_dest(ref_file_path, result_file_path, df_src, start_row_index):\n",
    "    # Путь к файлу Excel\n",
    "    wb = load_workbook(ref_file_path)\n",
    "    ws = wb.active  # или wb['SheetName']\n",
    "\n",
    "    # Поля файла-приёмника\n",
    "    row_header = [cell.value for cell in ws[1]]\n",
    "\n",
    "    # Сопоставление колонок\n",
    "    src_cols_lower = {col.lower(): col for col in df_src.columns}\n",
    "    ws_cols_lower = {i: str(header).strip().lower() if header else \"\" for i, header in enumerate(row_header)}\n",
    "    matched_columns = []\n",
    "    common_cols = set()\n",
    "    nomenclature_col_idx = None\n",
    "\n",
    "    for col_idx, header_lower in ws_cols_lower.items():\n",
    "        if header_lower == \"номенклатура\":\n",
    "            nomenclature_col_idx = col_idx\n",
    "        if header_lower in src_cols_lower:\n",
    "            matched_columns.append((col_idx, src_cols_lower[header_lower]))\n",
    "            common_cols.add(src_cols_lower[header_lower])\n",
    "\n",
    "    if nomenclature_col_idx is None:\n",
    "        raise ValueError(\"Колонка 'Номенклатура' не найдена в файле-приёмнике\")\n",
    "\n",
    "    # Считываем значения \"Номенклатура\"\n",
    "    nomenclature_values = []\n",
    "    for i in range(len(df_src)):\n",
    "        cell_value = ws.cell(row=start_row_index + i, column=nomenclature_col_idx + 1).value\n",
    "        nomenclature_values.append(cell_value)\n",
    "\n",
    "    # Запись данных\n",
    "    for i, (_, row_src) in enumerate(df_src.iterrows()):\n",
    "        for col_idx, src_col in matched_columns:\n",
    "            cell = ws.cell(row=start_row_index + i, column=col_idx + 1)\n",
    "            if cell.value in [None, \"\"]:\n",
    "                cell.value = row_src[src_col]\n",
    "\n",
    "    # Сохранение\n",
    "    wb.save(result_file_path)\n",
    "\n",
    "    # Подготовка выходного DataFrame\n",
    "    result_df = df_src[list(common_cols)].copy()\n",
    "    result_df.insert(0, \"Номенклатура\", pd.Series(nomenclature_values))\n",
    "\n",
    "    return result_df, common_cols\n",
    "\n",
    "# -------------------------------------------Сохранить незаписанные данные в дополнительные колонки или отдельный файл-------------------------------------------\n",
    "\n",
    "def append_dataframe_to_excel(df: pd.DataFrame, file_path: str, result_path: str, start_row: int):\n",
    "    # Проверка, существует ли файл\n",
    "    if os.path.exists(file_path):\n",
    "        wb = load_workbook(file_path)\n",
    "    else:\n",
    "        # Если файла нет, создаем новый\n",
    "        wb = Workbook()\n",
    "    \n",
    "    ws = wb.active\n",
    "\n",
    "    # Найдём первую пустую ячейку в первой строке\n",
    "    col_index = 1\n",
    "    while ws.cell(row=1, column=col_index).value is not None:\n",
    "        col_index += 1\n",
    "\n",
    "    # Записываем названия колонок DataFrame в первую строку, начиная с найденной колонки\n",
    "    for i, col_name in enumerate(df.columns):\n",
    "        ws.cell(row=1, column=col_index + i, value=col_name)\n",
    "\n",
    "    # Автонастройка ширины столбцов по первой строке\n",
    "    for col_idx, cell in enumerate(ws[1], start=col_index):\n",
    "        max_length = len(str(cell.value)) if cell.value else 0\n",
    "        col_letter = cell.column_letter\n",
    "        ws.column_dimensions[col_letter].width = max_length + 2  # +2 для отступа\n",
    "\n",
    "    # Применение стилей и переносов\n",
    "    for row in ws.iter_rows(min_row=2, max_row=ws.max_row, max_col=ws.max_column):\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(wrap_text=True, vertical='center')  # включаем перенос текста\n",
    "\n",
    "    # Записываем данные DataFrame начиная со start_row\n",
    "    for row_offset, row in enumerate(dataframe_to_rows(df, index=False, header=False)):\n",
    "        for i, value in enumerate(row):\n",
    "            ws.cell(row=start_row + row_offset, column=col_index + i, value=value)\n",
    "\n",
    "    # Сохраняем файл\n",
    "    wb.save(result_path)\n",
    "\n",
    "def save_missing(df1, filepath):\n",
    "\n",
    "    # Создаём ExcelWriter\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl') as writer:\n",
    "        row = 0\n",
    "\n",
    "        # Запись df1\n",
    "        df1.to_excel(writer, index=False, startrow=row)\n",
    "        row += len(df1) + 2  # +1 за заголовок, +1 за пустую строку\n",
    "\n",
    "        # Автоматическая установка ширины колонок\n",
    "        worksheet = writer.sheets['Sheet1']\n",
    "        for column_cells in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column = column_cells[0].column\n",
    "            for cell in column_cells:\n",
    "                if cell.value:\n",
    "                    max_length = max(max_length, len(str(cell.value)))\n",
    "            adjusted_width = max_length + 2\n",
    "            worksheet.column_dimensions[get_column_letter(column)].width = adjusted_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb24f723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Серия': 'V4000',\n",
       " 'Модель': 'FR4T-53003',\n",
       " 'Тип прибора': 'Встраиваемая морозильная камера',\n",
       " 'Страна бренда': 'Швейцария',\n",
       " 'Изготовитель': 'Фауцуг',\n",
       " 'Гарантия (кол-во лет)': '2',\n",
       " 'Ширина, мм': '600',\n",
       " 'Высота, мм': '1778',\n",
       " 'Цвет': 'Белый',\n",
       " 'Дизайнерский фасад': 'Под навес вашего фасада',\n",
       " 'Ручка': 'Без ручки',\n",
       " 'Тип управления': 'TouchControl',\n",
       " 'Дисплей': 'Цифровой дисплей',\n",
       " 'Объем, л': '213',\n",
       " 'Полезный объем морозильной камеры, л': '213',\n",
       " 'Размораживание морозильной камеры': 'No Frost',\n",
       " 'Механизм закрывания дверцы SoftClose/SoftClosePlus': 'Есть',\n",
       " 'Количество корзин, контейнеров, ящиков': '8',\n",
       " 'Дверные петли': 'Слева',\n",
       " 'Класс энергоэффективности': 'E',\n",
       " 'Уровень шума, Дб': '36',\n",
       " 'Климатический класс': 'SN-T',\n",
       " 'Длина сетевого кабеля, см': '220',\n",
       " 'Тип штекера': 'Schuko 16A',\n",
       " 'Габариты, мм': '1770х559х546',\n",
       " 'Габариты ниши для встраивания ВхШхГ, мм': '1780-1788х560-570х550',\n",
       " 'Глубина с открытой дверью, мм': '1137',\n",
       " 'Вес, кг': '82.5'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Протестировать функцию парсинга\n",
    "def test_parser(url, parser_func):\n",
    "    http = urllib3.PoolManager()\n",
    "    df_all = pd.DataFrame()\n",
    "    response = http.request('GET', url)\n",
    "    html_code = response.data.decode()\n",
    "    data = parser_func(html_code)\n",
    "    return data\n",
    "\n",
    "data = test_parser('https://vzug-shop.ru/catalog/kholodilniki/vstraivaemaya-morozilnaya-kamera-v-zug-freezer-v4000-178n-fr4t-53003/', parse_vzug_page)\n",
    "print(len(data))  # Должно вернуть количество характеристик, например 10\n",
    "data # Выводим результат парсинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a089da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------Добавить функции для сопоставления синонимов---------------------------------------------------------\n",
    "\n",
    "wordnet = RuWordNet()\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def get_normal_form(word):\n",
    "    return morph.parse(word)[0].normal_form\n",
    "\n",
    "def are_synonyms(word1, word2):\n",
    "    lemma1 = get_normal_form(word1)\n",
    "    lemma2 = get_normal_form(word2)\n",
    "\n",
    "    synsets1 = wordnet.get_synsets(lemma1)\n",
    "    synsets2 = wordnet.get_synsets(lemma2)\n",
    "\n",
    "    # Сравниваем наличие общих лемм в синсетах\n",
    "    for s1 in synsets1:\n",
    "        for s2 in synsets2:\n",
    "            if s1.id == s2.id:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def list_synonyms_comparison(list1, list2):\n",
    "    return [are_synonyms(word1, word2) for word1, word2 in zip(list1, list2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764e71c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Протестировать подбор синонимов\n",
    "list1 = ['Машина', 'Счастливый', 'Работать']\n",
    "list2 = ['автомобиля', 'счастливый', 'работник']\n",
    "list_synonyms_comparison(list1, list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571ce816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------Добавить функцию для обеспечения правильного дописывания данных основываясь на утверждённых синонимах-----------------------------\n",
    "\n",
    "def parse_custom_dict_line(line):\n",
    "    \"\"\"\n",
    "    Разбирает строку из словаря: <характеристика>: <синоним1>; <синоним2>; ...| <антисиноним1>, <антисиноним2>, ...\n",
    "    \"\"\"\n",
    "    base, *rest = line.strip().split(':')\n",
    "    if not rest:\n",
    "        return base.strip(), set(), set()\n",
    "    syn_ant = rest[0].split('|')\n",
    "    synonyms = set(map(str.strip, syn_ant[0].split(';'))) if syn_ant[0] else set()\n",
    "    antonyms = set(map(str.strip, syn_ant[1].split(','))) if len(syn_ant) > 1 else set()\n",
    "    return base.strip(), synonyms, antonyms\n",
    "\n",
    "def load_existing_synonyms(file_path):\n",
    "    syn_dict = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            base, synonyms, antonyms = parse_custom_dict_line(line)\n",
    "            syn_dict[base] = {'synonyms': synonyms, 'antonyms': antonyms}\n",
    "    return syn_dict\n",
    "\n",
    "def rename_columns_with_syn_dict(df, syn_dict_path, all_1c_chars_path):\n",
    "    # Загрузка словаря\n",
    "    synonyms_dict = load_existing_synonyms(syn_dict_path)\n",
    "    all_chars = pd.read_excel(all_1c_chars_path, header=None).iloc[0].astype(str).tolist()\n",
    "    all_chars_lower = [char.lower() for char in all_chars]  # Приводим к нижнему регистру для сравнения\n",
    "\n",
    "    # Удаление дублирующихся колонок по имени\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    # Поиск синонимичных имен колонок через словарь\n",
    "    df_expanded = df.copy()\n",
    "    unsyn_set = set()\n",
    "    for col in df.columns:\n",
    "        flag = False\n",
    "        for synonym_key, syn_data in synonyms_dict.items():\n",
    "            syn_set = syn_data.get(\"synonyms\", set())\n",
    "            if col in syn_set:\n",
    "                # Добавляем колонку с именем synonym_key, если она отличается и ещё не существует\n",
    "                if synonym_key != col and synonym_key not in df_expanded.columns:\n",
    "                    df_expanded[synonym_key] = df[col]\n",
    "                    flag = True\n",
    "        if flag:\n",
    "            # Если колонка была переименована, удаляем оригинальную\n",
    "            df_expanded.drop(columns=[col], inplace=True)\n",
    "        elif col.lower() in all_chars_lower:\n",
    "            df_expanded[col.upper()] = df[col]\n",
    "            df_expanded.drop(columns=[col], inplace=True)\n",
    "        else:\n",
    "            unsyn_set.add(col)\n",
    "\n",
    "    return df_expanded, unsyn_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6bcdd",
   "metadata": {},
   "source": [
    "# Варианты запуска парсинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194aa8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.70s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Тип</th>\n",
       "      <th>Вид</th>\n",
       "      <th>Высота (см)</th>\n",
       "      <th>Ширина (см)</th>\n",
       "      <th>Глубина (см)</th>\n",
       "      <th>Габариты (ВхШхГ) (см)</th>\n",
       "      <th>Габариты ниши для встраивания (ВхШхГ) (см)</th>\n",
       "      <th>Количество камер</th>\n",
       "      <th>Количество дверей</th>\n",
       "      <th>Дверной упор</th>\n",
       "      <th>...</th>\n",
       "      <th>Мощность подключения (Вт)</th>\n",
       "      <th>Уровень шума (дб)</th>\n",
       "      <th>Длина шнура электропитания (м)</th>\n",
       "      <th>Вес нетто (кг)</th>\n",
       "      <th>Возможность перевешивания двери</th>\n",
       "      <th>Монтаж двери</th>\n",
       "      <th>Регулируемые ножки</th>\n",
       "      <th>Индикаторы</th>\n",
       "      <th>Индикация открытой двери</th>\n",
       "      <th>Артикул</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Встраиваемый</td>\n",
       "      <td>Морозильник</td>\n",
       "      <td>178.5</td>\n",
       "      <td>54</td>\n",
       "      <td>54.5</td>\n",
       "      <td>178.5х54х54.5</td>\n",
       "      <td>177.6-178.4х56-56.5х56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Слева</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>41</td>\n",
       "      <td>1.975</td>\n",
       "      <td>67</td>\n",
       "      <td>Да</td>\n",
       "      <td>Скользящее крепление двери (система door sliding)</td>\n",
       "      <td>Да</td>\n",
       "      <td>Температуры морозильного отделения</td>\n",
       "      <td>Да</td>\n",
       "      <td>00000020289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Тип          Вид Высота (см) Ширина (см) Глубина (см)  \\\n",
       "0          None         None        None        None         None   \n",
       "1  Встраиваемый  Морозильник       178.5          54         54.5   \n",
       "\n",
       "  Габариты (ВхШхГ) (см) Габариты ниши для встраивания (ВхШхГ) (см)  \\\n",
       "0                  None                                       None   \n",
       "1         178.5х54х54.5                     177.6-178.4х56-56.5х56   \n",
       "\n",
       "  Количество камер Количество дверей Дверной упор  ...  \\\n",
       "0             None              None         None  ...   \n",
       "1                1                 1        Слева  ...   \n",
       "\n",
       "  Мощность подключения (Вт) Уровень шума (дб) Длина шнура электропитания (м)  \\\n",
       "0                      None              None                           None   \n",
       "1                        65                41                          1.975   \n",
       "\n",
       "  Вес нетто (кг) Возможность перевешивания двери  \\\n",
       "0           None                            None   \n",
       "1             67                              Да   \n",
       "\n",
       "                                        Монтаж двери Регулируемые ножки  \\\n",
       "0                                               None               None   \n",
       "1  Скользящее крепление двери (система door sliding)                 Да   \n",
       "\n",
       "                           Индикаторы Индикация открытой двери      Артикул  \n",
       "0                                None                     None         None  \n",
       "1  Температуры морозильного отделения                       Да  00000020289  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------Запуск парсинга и сохранение результатов-----------------------------------------------------------\n",
    "\n",
    "# Протестировать запись одной строки с двух сайтов\n",
    "from argparse import Namespace\n",
    "\n",
    "# housedorf\n",
    "args = Namespace(start_row=33, append=True, site='housedorf', urls_source='input_example/url_housedorf.txt', input_path='input_example/example.xlsx', output_path='result_housedorf.xlsx')\n",
    "if not args.output_path:\n",
    "    raise ValueError(\"there's not enough arguments\")\n",
    "\n",
    "# Проверка, не повреждены ли входные файлы\n",
    "wb = load_workbook(args.input_path)\n",
    "\n",
    "if args.site == 'korting':\n",
    "    df_src = create_src(args.urls_source, parse_korting_page)\n",
    "elif args.site == 'housedorf':\n",
    "    df_src = create_src(args.urls_source, parse_hausedorf_page)\n",
    "elif args.site == 'dedietrich':\n",
    "    df_src = create_src(args.urls_source, parse_dedietrich_page)\n",
    "elif args.site == 'falmec':\n",
    "    df_src = create_src(args.urls_source, parse_falmec_page)\n",
    "elif args.site == 'vzug':\n",
    "    df_src = create_src(args.urls_source, parse_vzug_page)\n",
    "else:\n",
    "    raise ValueError(\"There're no parse function for this site\")\n",
    "\n",
    "df_src, unsyn_set = rename_columns_with_syn_dict(df_src, synonyms_path, all_characteristics_path) # Для обеспечения правильного дописывания данных и для корректного входа к функции, \n",
    "                                                                        # генерирующей отчёт\n",
    "resultdf, com_cols = write_dest(args.input_path, args.output_path, df_src, args.start_row)\n",
    "resultdf.to_parquet(f\"{args.site}_auxiliary.parquet\")\n",
    "\n",
    "com_cols = resultdf.columns.intersection(df_src.columns)\n",
    "missingdf = df_src.drop(columns=com_cols).copy()\n",
    "print(unsyn_set)\n",
    "with open(f'unaccepted_syn_{args.site}.txt', 'w') as f:\n",
    "    f.write('; '.join(map(str, unsyn_set)))\n",
    "\n",
    "if args.append:\n",
    "    append_dataframe_to_excel(missingdf, args.output_path, args.output_path, args.start_row)\n",
    "else:\n",
    "    missingdf.insert(0, 'Номенклатура', resultdf['Номенклатура'].copy())\n",
    "    save_missing(missingdf, f'missing_{args.site}.xlsx')\n",
    "\n",
    "# korting\n",
    "args = Namespace(start_row=34, append=False, site='korting', urls_source='input_example/url_korting.txt', input_path='result_housedorf.xlsx', output_path='result.xlsx')\n",
    "if not args.output_path:\n",
    "    raise ValueError(\"there's not enough arguments\")\n",
    "\n",
    "# Проверка, не повреждены ли входные файлы\n",
    "wb = load_workbook(args.input_path)\n",
    "\n",
    "if args.site == 'korting':\n",
    "    df_src = create_src(args.urls_source, parse_korting_page)\n",
    "elif args.site == 'housedorf':\n",
    "    df_src = create_src(args.urls_source, parse_hausedorf_page)\n",
    "elif args.site == 'dedietrich':\n",
    "    df_src = create_src(args.urls_source, parse_dedietrich_page)\n",
    "elif args.site == 'falmec':\n",
    "    df_src = create_src(args.urls_source, parse_falmec_page)\n",
    "elif args.site == 'vzug':\n",
    "    df_src = create_src(args.urls_source, parse_vzug_page)\n",
    "else:\n",
    "    raise ValueError(\"There're no parse function for this site\")\n",
    "\n",
    "df_src, unsyn_set = rename_columns_with_syn_dict(df_src, synonyms_path, all_characteristics_path) # Для обеспечения правильного дописывания данных и для корректного входа к функции, \n",
    "                                                                        # генерирующей отчёт\n",
    "resultdf, com_cols = write_dest(args.input_path, args.output_path, df_src, args.start_row)\n",
    "resultdf.to_parquet(f\"{args.site}_auxiliary.parquet\")\n",
    "\n",
    "com_cols = resultdf.columns.intersection(df_src.columns)\n",
    "missingdf = df_src.drop(columns=com_cols).copy()\n",
    "print(unsyn_set)\n",
    "with open(f'unaccepted_syn_{args.site}.txt', 'w') as f:\n",
    "    f.write('; '.join(map(str, unsyn_set)))\n",
    "\n",
    "if args.append:\n",
    "    append_dataframe_to_excel(missingdf, args.output_path, args.output_path, args.start_row)\n",
    "else:\n",
    "    missingdf.insert(0, 'Номенклатура', resultdf['Номенклатура'].copy())\n",
    "    save_missing(missingdf, f'missing_{args.site}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ef97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dedietrich + housedorf\n",
    "from argparse import Namespace\n",
    "\n",
    "# housedorf\n",
    "args = Namespace(start_row=2, append=True, site='housedorf', urls_source='urls_housedorf.txt', input_path='example.xlsx', output_path='result_housedorf.xlsx')\n",
    "if not args.output_path:\n",
    "    raise ValueError(\"there's not enough arguments\")\n",
    "\n",
    "# Проверка, не повреждены ли входные файлы\n",
    "wb = load_workbook(args.input_path)\n",
    "\n",
    "if args.site == 'korting':\n",
    "    df_src = create_src(args.urls_source, parse_korting_page)\n",
    "elif args.site == 'housedorf':\n",
    "    df_src = create_src(args.urls_source, parse_hausedorf_page)\n",
    "elif args.site == 'dedietrich':\n",
    "    df_src = create_src(args.urls_source, parse_dedietrich_page)\n",
    "elif args.site == 'falmec':\n",
    "    df_src = create_src(args.urls_source, parse_falmec_page)\n",
    "elif args.site == 'vzug':\n",
    "    df_src = create_src(args.urls_source, parse_vzug_page)\n",
    "else:\n",
    "    raise ValueError(\"There're no parse function for this site\")\n",
    "\n",
    "df_src, unsyn_set = rename_columns_with_syn_dict(df_src, synonyms_path, all_characteristics_path) # Для обеспечения правильного дописывания данных и для корректного входа к функции, \n",
    "                                                                        # генерирующей отчёт\n",
    "resultdf, com_cols = write_dest(args.input_path, args.output_path, df_src, args.start_row)\n",
    "resultdf.to_parquet(f\"{args.site}_auxiliary.parquet\")\n",
    "\n",
    "com_cols = resultdf.columns.intersection(df_src.columns)\n",
    "missingdf = df_src.drop(columns=com_cols).copy()\n",
    "print(unsyn_set)\n",
    "with open(f'unaccepted_syn_{args.site}.txt', 'w') as f:\n",
    "    f.write('; '.join(map(str, unsyn_set)))\n",
    "\n",
    "if args.append:\n",
    "    append_dataframe_to_excel(missingdf, args.output_path, args.output_path, args.start_row)\n",
    "else:\n",
    "    missingdf.insert(0, 'Номенклатура', resultdf['Номенклатура'].copy())\n",
    "    save_missing(missingdf, f'missing_{args.site}.xlsx')\n",
    "\n",
    "\n",
    "args = Namespace(start_row=34, append=False, site='falmec', urls_source='urls_falmec.txt', input_path='result_housedorf.xlsx', output_path='result.xlsx')\n",
    "if not args.output_path:\n",
    "    raise ValueError(\"there's not enough arguments\")\n",
    "\n",
    "# Проверка, не повреждены ли входные файлы\n",
    "wb = load_workbook(args.input_path)\n",
    "\n",
    "if args.site == 'korting':\n",
    "    df_src = create_src(args.urls_source, parse_korting_page)\n",
    "elif args.site == 'housedorf':\n",
    "    df_src = create_src(args.urls_source, parse_hausedorf_page)\n",
    "elif args.site == 'dedietrich':\n",
    "    df_src = create_src(args.urls_source, parse_dedietrich_page)\n",
    "elif args.site == 'falmec':\n",
    "    df_src = create_src(args.urls_source, parse_falmec_page)\n",
    "elif args.site == 'vzug':\n",
    "    df_src = create_src(args.urls_source, parse_vzug_page)\n",
    "else:\n",
    "    raise ValueError(\"There're no parse function for this site\")\n",
    "\n",
    "df_src, unsyn_set = rename_columns_with_syn_dict(df_src, synonyms_path, all_characteristics_path) # Для обеспечения правильного дописывания данных и для корректного входа к функции, \n",
    "                                                                        # генерирующей отчёт\n",
    "resultdf, com_cols = write_dest(args.input_path, args.output_path, df_src, args.start_row)\n",
    "resultdf.to_parquet(f\"{args.site}_auxiliary.parquet\")\n",
    "\n",
    "com_cols = resultdf.columns.intersection(df_src.columns)\n",
    "missingdf = df_src.drop(columns=com_cols).copy()\n",
    "print(unsyn_set)\n",
    "with open(f'unaccepted_syn_{args.site}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('; '.join(map(str, unsyn_set)))\n",
    "\n",
    "if args.append:\n",
    "    append_dataframe_to_excel(missingdf, args.output_path, args.output_path, args.start_row)\n",
    "else:\n",
    "    missingdf.insert(0, 'Номенклатура', resultdf['Номенклатура'].copy())\n",
    "    save_missing(missingdf, f'missing_{args.site}.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc06f5",
   "metadata": {},
   "source": [
    "# Программа generate_syn_report.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c2cfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ruwordnet import RuWordNet\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from itertools import product\n",
    "\n",
    "synonyms_path='synonyms.txt'\n",
    "all_characteristics_path='all_characteristics.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a23905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------Добавить функции для сопоставления синонимов---------------------------------------------------------\n",
    "\n",
    "wordnet = RuWordNet()\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def get_normal_form(word):\n",
    "    return morph.parse(word)[0].normal_form\n",
    "\n",
    "def are_synonyms(word1, word2):\n",
    "    lemma1 = get_normal_form(word1)\n",
    "    lemma2 = get_normal_form(word2)\n",
    "\n",
    "    synsets1 = wordnet.get_synsets(lemma1)\n",
    "    synsets2 = wordnet.get_synsets(lemma2)\n",
    "\n",
    "    # Сравниваем наличие общих лемм в синсетах\n",
    "    for s1 in synsets1:\n",
    "        for s2 in synsets2:\n",
    "            if s1.id == s2.id:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def list_synonyms_comparison(list1, list2):\n",
    "    return [are_synonyms(word1, word2) for word1, word2 in zip(list1, list2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cdbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------Добавить функцию для создания отчёта о сопоставлении колонок тем, что уже существуют в 1С-----------------------------------\n",
    "\n",
    "def parse_custom_dict_line(line):\n",
    "    \"\"\"\n",
    "    Разбирает строку из словаря: <характеристика>: <синоним1>; <синоним2>; ...| <антисиноним1>, <антисиноним2>, ...\n",
    "    \"\"\"\n",
    "    base, *rest = line.strip().split(':')\n",
    "    if not rest:\n",
    "        return base.strip(), set(), set()\n",
    "    syn_ant = rest[0].split('|')\n",
    "    synonyms = set(map(str.strip, syn_ant[0].split(';'))) if syn_ant[0] else set()\n",
    "    antonyms = set(map(str.strip, syn_ant[1].split(','))) if len(syn_ant) > 1 else set()\n",
    "    return base.strip(), synonyms, antonyms\n",
    "\n",
    "def load_existing_synonyms(file_path):\n",
    "    syn_dict = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            base, synonyms, antonyms = parse_custom_dict_line(line)\n",
    "            syn_dict[base] = {'synonyms': synonyms, 'antonyms': antonyms}\n",
    "    return syn_dict\n",
    "\n",
    "def tokenize(text):\n",
    "    return set(re.findall(r'\\w+', text.lower()))\n",
    "\n",
    "def are_words_possibly_synonyms(words1, words2, are_synonims_func):\n",
    "    pairs = product(words1, words2)\n",
    "    for w1, w2 in pairs:\n",
    "        if w1 == w2:\n",
    "            return True\n",
    "        if are_synonims_func(w1, w2):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def generate_synonym_report(existing_dict_path, all_1c_chars_path, new_chars, are_synonims_func, output_excel_path):\n",
    "    custom_dict = load_existing_synonyms(existing_dict_path)\n",
    "    all_chars = pd.read_excel(all_1c_chars_path, header=None).iloc[0].astype(str).tolist()\n",
    "    result_rows = []\n",
    "\n",
    "    for c1 in tqdm(all_chars):\n",
    "        for c2 in new_chars:\n",
    "            if c1 == c2:\n",
    "                continue\n",
    "            tokens1 = tokenize(c1)\n",
    "            tokens2 = tokenize(c2)\n",
    "            if are_words_possibly_synonyms(tokens1, tokens2, are_synonims_func):\n",
    "                result_rows.append((c1, c2, None))  # None для ручной отметки\n",
    "\n",
    "    df_result = pd.DataFrame(result_rows, columns=[\"base_char\", \"compared_char\", \"label\"])\n",
    "    df_result.to_excel(output_excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1c109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Срок гарантии (мес.)', 'Габариты (ВхШхГ) (мм)', 'Тип охлаждения холодильной камеры', 'Тип разморозки морозильной камеры', 'Сигнализация открытой двери', 'Приветственный сигнал при открытии дверцы', 'Крепление фасада']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------Запуск генерации-----------------------------------------------------------------------\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(site='korting', synonyms_report_path='syn_report_korting.xlsx')\n",
    "if not args.synonyms_report_path:\n",
    "    raise ValueError(\"there's not enough arguments\")\n",
    "\n",
    "with open(f'unaccepted_syn_{args.site}.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "\n",
    "unsyn_list = list(map(str, data.strip().split('; ')))\n",
    "\n",
    "generate_synonym_report(\n",
    "    synonyms_path,\n",
    "    all_characteristics_path,\n",
    "    unsyn_list,\n",
    "    are_synonyms,\n",
    "    args.synonyms_report_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c5bd6",
   "metadata": {},
   "source": [
    "# Программа synonyms_dict_update.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6afd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import argparse\n",
    "synonyms_path='synonyms.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd4a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------Обновить словарь синонимов из Excel--------------------------------------------------------------\n",
    "def load_synonym_dict(dict_path):\n",
    "    syn_dict = defaultdict(lambda: {\"synonyms\": set(), \"antisynonyms\": set()})\n",
    "    if not os.path.exists(dict_path):\n",
    "        return syn_dict\n",
    "    \n",
    "    with open(dict_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            key, rest = line.strip().split(\":\", 1)\n",
    "            syn_part, *anti_part = rest.strip().split(\"|\")\n",
    "            syns = set(map(str.strip, syn_part.strip().split(\";\"))) if syn_part.strip() else set()\n",
    "            antis = set(map(str.strip, anti_part[0].strip().split(\",\"))) if anti_part and anti_part[0].strip() else set()\n",
    "            syn_dict[key.strip()][\"synonyms\"].update(syns)\n",
    "            syn_dict[key.strip()][\"antisynonyms\"].update(antis)\n",
    "    return syn_dict\n",
    "\n",
    "\n",
    "def save_synonym_dict(syn_dict, dict_path):\n",
    "    with open(dict_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for key in sorted(syn_dict.keys()):\n",
    "            syns = \"; \".join(sorted(syn_dict[key][\"synonyms\"]))\n",
    "            antis = \", \".join(sorted(syn_dict[key][\"antisynonyms\"]))\n",
    "            line = f\"{key}: {syns} | {antis}\\n\"\n",
    "            f.write(line)\n",
    "\n",
    "\n",
    "def update_synonym_dict_from_excel(excel_path, dict_path):\n",
    "    df = pd.read_excel(excel_path)\n",
    "    if not {\"base_char\", \"compared_char\", \"label\"}.issubset(df.columns):\n",
    "        raise ValueError(\"Excel должен содержать столбцы: base_char, compared_char, label\")\n",
    "    \n",
    "    syn_dict = load_synonym_dict(dict_path)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        base = row[\"base_char\"].strip()\n",
    "        comp = row[\"compared_char\"].strip()\n",
    "        label = row[\"label\"]\n",
    "\n",
    "        if label == 1:\n",
    "            syn_dict[base][\"synonyms\"].add(comp)\n",
    "        elif label == 0 or pd.isna(label):\n",
    "            syn_dict[base][\"antisynonyms\"].add(comp)\n",
    "        else:\n",
    "            continue  # Пропустить некорректные значения\n",
    "\n",
    "    # Удалить пересекающиеся значения\n",
    "    for base in syn_dict:\n",
    "        overlap = syn_dict[base][\"synonyms\"] & syn_dict[base][\"antisynonyms\"]\n",
    "        syn_dict[base][\"antisynonyms\"] -= overlap\n",
    "\n",
    "    save_synonym_dict(syn_dict, dict_path)\n",
    "    print(f\"Обновлённый словарь сохранён в {dict_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441d8486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обновлённый словарь сохранён в synonyms.txt\n"
     ]
    }
   ],
   "source": [
    "# Протестировать обновление файла-словаря\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "# housedorf\n",
    "args = Namespace(report_path='syn_report_housedorf.xlsx')\n",
    "if not args.report_path:\n",
    "    raise ValueError(\"there's not enough arguments\")\n",
    "\n",
    "update_synonym_dict_from_excel(args.report_path, synonyms_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee85889",
   "metadata": {},
   "source": [
    "# Программа compare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import PatternFill, Alignment\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import argparse\n",
    "from itertools import product\n",
    "from ruwordnet import RuWordNet\n",
    "import pymorphy2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57f42b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------Добавить функции для сопоставления синонимов---------------------------------------------------------\n",
    "\n",
    "wordnet = RuWordNet()\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def get_normal_form(word):\n",
    "    return morph.parse(word)[0].normal_form\n",
    "\n",
    "def are_synonyms(word1, word2):\n",
    "    lemma1 = get_normal_form(word1)\n",
    "    lemma2 = get_normal_form(word2)\n",
    "\n",
    "    synsets1 = wordnet.get_synsets(lemma1)\n",
    "    synsets2 = wordnet.get_synsets(lemma2)\n",
    "\n",
    "    # Сравниваем наличие общих лемм в синсетах\n",
    "    for s1 in synsets1:\n",
    "        for s2 in synsets2:\n",
    "            if s1.id == s2.id:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def tokenize(text):\n",
    "    return set(re.findall(r'\\w+', text.lower()))\n",
    "\n",
    "def are_words_possibly_synonyms(words1, words2, are_synonims_func):\n",
    "    pairs = product(words1, words2)\n",
    "    for w1, w2 in pairs:\n",
    "        if w1 == w2:\n",
    "            return True\n",
    "        if are_synonims_func(w1, w2):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8b87f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------Сравнить записанные данные-------------------------------------------------------------------\n",
    "\n",
    "def compare_dataframes(df1: pd.DataFrame, df2: pd.DataFrame, name1: str = 'df1', name2: str = 'df2') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Сравнивает два DataFrame по общим столбцам, включая \"Номенклатура\" как ключ.\n",
    "    Добавляет префиксы к столбцам (кроме \"Номенклатура\") и формирует колонку diff_columns.\n",
    "    \"\"\"\n",
    "    if 'Номенклатура' not in df1.columns or 'Номенклатура' not in df2.columns:\n",
    "        raise ValueError(\"Оба DataFrame должны содержать колонку 'Номенклатура'\")\n",
    "\n",
    "    # Определим общие характеристики (кроме \"Номенклатура\")\n",
    "    common_columns = df1.columns.intersection(df2.columns).difference(['Номенклатура'])\n",
    "\n",
    "    # Сузим входные DataFrame'ы до нужных колонок\n",
    "    df1_reduced = df1[['Номенклатура'] + list(common_columns)].copy()\n",
    "    df2_reduced = df2[['Номенклатура'] + list(common_columns)].copy()\n",
    "\n",
    "    # Переименуем характеристики с префиксами, \"Номенклатура\" оставим без изменений\n",
    "    df1_renamed = df1_reduced.rename(columns={col: f'{name1}_{col}' for col in common_columns})\n",
    "    df2_renamed = df2_reduced.rename(columns={col: f'{name2}_{col}' for col in common_columns})\n",
    "\n",
    "    # Объединение по \"Номенклатура\"\n",
    "    df_merged = pd.merge(df1_renamed, df2_renamed, on='Номенклатура', how='outer')\n",
    "\n",
    "    # Функция для сравнения значений по строке\n",
    "    def get_differences(row):\n",
    "        diffs = []\n",
    "        for col in common_columns:\n",
    "            val1 = row.get(f'{name1}_{col}', None)\n",
    "            val2 = row.get(f'{name2}_{col}', None)\n",
    "            if pd.isna(val1) or pd.isna(val2):\n",
    "                continue\n",
    "            else:\n",
    "                tokens1 = tokenize(str(val1))\n",
    "                tokens2 = tokenize(str(val2))\n",
    "                if not are_words_possibly_synonyms(tokens1, tokens2, are_synonyms):\n",
    "                    diffs.append(col)\n",
    "        return ', '.join(diffs)\n",
    "\n",
    "    # Добавление столбца с различиями\n",
    "    df_merged['diff_columns'] = df_merged.apply(get_differences, axis=1)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "# --------------------------------------------------------------Сохранить результат сравнения в excel--------------------------------------------------------------\n",
    "\n",
    "def save_comparison_to_excel(df: pd.DataFrame, filename: str):\n",
    "    red_fill = PatternFill(start_color=\"FFC7CE\", end_color=\"FFC7CE\", fill_type=\"solid\")\n",
    "    yellow_fill = PatternFill(start_color=\"FFEB9C\", end_color=\"FFEB9C\", fill_type=\"solid\")\n",
    "\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "\n",
    "    # Записываем DataFrame в Excel\n",
    "    for r in dataframe_to_rows(df, index=False, header=True):\n",
    "        ws.append(r)\n",
    "\n",
    "    headers = [cell.value for cell in ws[1]]\n",
    "    diff_col_index = len(headers)\n",
    "    prefix_columns = [col for col in headers if col != 'Номенклатура' and col != 'diff_columns']\n",
    "\n",
    "    # Автонастройка ширины столбцов по первой строке\n",
    "    for col_idx, cell in enumerate(ws[1], start=1):\n",
    "        max_length = len(str(cell.value)) if cell.value else 0\n",
    "        col_letter = cell.column_letter\n",
    "        ws.column_dimensions[col_letter].width = max_length + 2  # +2 для отступа\n",
    "\n",
    "    # Применение стилей и переносов\n",
    "    for row in ws.iter_rows(min_row=2, max_row=ws.max_row, max_col=ws.max_column):\n",
    "        diff_text = row[diff_col_index - 1].value\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(wrap_text=True, vertical='center')  # включаем перенос текста\n",
    "\n",
    "        if isinstance(diff_text, str) and diff_text.strip():\n",
    "            different_fields = [field.strip() for field in diff_text.split(',')]\n",
    "            for diff_field in different_fields:\n",
    "                for col_idx, col_name in enumerate(headers):\n",
    "                    if col_name.endswith(f\"_{diff_field}\"):\n",
    "                        row[col_idx].fill = yellow_fill\n",
    "        row[diff_col_index - 1].fill = red_fill\n",
    "\n",
    "    wb.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3398e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Протестировать сравнение двух DataFrame и сохранение результата в excel\n",
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(site1='korting', site2='housedorf')\n",
    "if not args.site2:\n",
    "    raise ValueError(\"there's not enough arguments\")\n",
    "if args.site1 == args.site2:\n",
    "    raise ValueError(\"the arguments coincide, comparison is impossible\")\n",
    "\n",
    "resultdf_1 = pd.read_parquet(f\"{args.site1}_auxiliary.parquet\")\n",
    "resultdf_2 = pd.read_parquet(f\"{args.site2}_auxiliary.parquet\")\n",
    "comp_result = compare_dataframes(resultdf_1, resultdf_2, args.site1, args.site2)\n",
    "\n",
    "save_comparison_to_excel(comp_result, f'comparison_{args.site1}_vs_{args.site2}.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
